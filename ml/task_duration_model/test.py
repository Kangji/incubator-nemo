import xgboost as xgb
import os

# simple example
# load file from text file, also binary buffer generated by xgboost
dtrain = xgb.DMatrix(os.path.join('dataset.txt.train'))
dtest = xgb.DMatrix(os.path.join('dataset.txt.test'))

# specify parameters via map, definition are same as c++ version
param = {'booster': 'gbtree', 'max_depth': 6, 'eta': 0.8, 'objective': 'reg:squarederror', "gamma": 0.8}

# specify validations set to watch performance
watchlist = [(dtest, 'eval'), (dtrain, 'train')]
num_round = 5
bst = xgb.train(param, dtrain, num_round, watchlist)

# this is prediction
preds = bst.predict(dtest)
labels = dtest.get_label()
for i in range(len(preds)):
	print('compare {} with {}'.format(preds[i], labels[i]))
print('error=%f' %
      (sum(1 for i in range(len(preds)) if abs(preds[i] - labels[i]) > labels[i]/2) /
       float(len(preds))))
bst.save_model('0001.model')
# dump model
bst.dump_model('dump.raw.txt')
# dump model with feature map
# bst.dump_model('dump.nice.txt', 'featmap.txt')
